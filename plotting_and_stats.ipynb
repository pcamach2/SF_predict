{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# create a function for performing the paired t-test \n",
    "#     and for calculating the effect size of the paired t-test\n",
    "#     and also returning the means of the two samples\n",
    "def wilcoxon(x,y,alternative='two-sided'):\n",
    "    # t-test from scipy.stats\n",
    "    t_statistic, p_value = ttest_rel(x,y,alternative=alternative)\n",
    "    # Calculate effect size (Cohen's d)\n",
    "    mean_diff = np.mean(x - y)\n",
    "    mean_x = np.mean(x)\n",
    "    mean_y = np.mean(y)\n",
    "    pooled_std = np.sqrt((np.std(x) ** 2 + np.std(y) ** 2) / 2)\n",
    "    d = mean_diff / pooled_std\n",
    "    return t_statistic, p_value, d, mean_x, mean_y\n",
    "\n",
    "# create a function for performing the shapiro-wilk test for normality\n",
    "#     of differences between two paired samples and for creating a qq plot\n",
    "#     of the differences between the two paired samples\n",
    "def shapiro_wilk_qq(x,y,recon1,recon2,walk_length):\n",
    "    # shapiro-wilk test for normality\n",
    "    shapiro_stat, shapiro_p = stats.shapiro(x-y)\n",
    "    # # make figure\n",
    "    # plt.figure(figsize=(8,6))\n",
    "    # # qq plot\n",
    "    # qq = stats.probplot(x-y, dist=\"norm\", plot=plt)\n",
    "    # # plot name\n",
    "    # # qq_plot_name = '/datain/dataset/plots/normality/qq_plot_differences'+str(x)+'_'+str(y)+'.png' # Uncomment for use in singularity\n",
    "    # qq_plot_name = '/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/plots/normality/qq_plot_differences'+str(recon1)+'_'+str(recon2)+'_walklength_'+str(walk_length)+'.png'\n",
    "    # # make matplotlib plot\n",
    "    # plt.title('QQ Plot for Differences between '+str(recon1)+' and '+str(recon2))\n",
    "    # plt.xlabel('Theoretical Quantiles')\n",
    "    # plt.ylabel('Ordered Values')\n",
    "    # plt.tight_layout()\n",
    "    # # save qq plot\n",
    "    # plt.savefig(qq_plot_name)\n",
    "    # plt.close()\n",
    "    return shapiro_stat, shapiro_p\n",
    "\n",
    "# create a function for performing the wilcoxon signed rank test with paired samples \n",
    "#     and calculating the effect size of the paired samples wilcoxon signed rank test\n",
    "#     and also returning the medians of the two samples\n",
    "def wilcoxon_test(x,y,alternative='two-sided'):\n",
    "    w_statistic, p_value = stats.wilcoxon(x,y,alternative=alternative,zero_method='pratt',mode='exact')\n",
    "    median_x = np.median(x)\n",
    "    median_y = np.median(y)\n",
    "    # Calculate effect size (r)\n",
    "    r = w_statistic / (len(x) * (len(y) + 1) / 2)\n",
    "    return w_statistic, p_value, r, median_x, median_y\n",
    "\n",
    "\n",
    "# create a function that reads a dataframe and returns a dataframe with the\n",
    "#     values of column i for which the row values in the 'Recon 1' column equal to recon1 \n",
    "#     and the values in the 'Recon 2' column equal to recon2\n",
    "def get_df_int(df,recon1,recon2,i):\n",
    "    if i is not None:\n",
    "        df_i = df[(df['Recon 1'][i] == recon1) & (df['Recon 2'][i] == recon2)]\n",
    "    else:\n",
    "        df_i = df[(df['Recon 1'] == recon1) & (df['Recon 2'] == recon2)]\n",
    "    return df_i\n",
    "\n",
    "# # create a function for calculating the mean, standard deviation, and median of the\n",
    "# #     values in each column of a dataframe - where the 'Recon 1' is equal to recon1\n",
    "# #     and 'Recon 2' is equal to recon2\n",
    "# def get_stats(df,recon1,recon2):\n",
    "#     df_i = df.loc[(df['Recon 1'] == recon1) & (df['Recon 2'] == recon2)]\n",
    "#     mean = df_i.mean(axis=0)\n",
    "#     std = df_i.std(axis=0)\n",
    "#     median = df_i.median(axis=0)\n",
    "#     return mean, std, median\n",
    "\n",
    "def print_stats(df):\n",
    "    print('Mean:')\n",
    "    print(df.mean(axis=0))\n",
    "    print('Standard Deviation:')\n",
    "    print(df.std(axis=0))\n",
    "    print('Median:')\n",
    "    print(df.median(axis=0))\n",
    "    print('Min:')\n",
    "    print(df.min(axis=0))\n",
    "    print('Max:')\n",
    "    print(df.max(axis=0))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in files and perform statistical tests of independence for Pearson scores at each walk length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5429474711418152\n",
      "0.05972728505730629\n",
      "0.5429474711418152\n",
      "0.5827040672302246\n",
      "0.05972728505730629\n",
      "0.5827043056488037\n",
      "0.9461228251457214\n",
      "0.10012679547071457\n",
      "0.9461228251457214\n",
      "0.9695802927017212\n",
      "0.10012679547071457\n",
      "0.9695802927017212\n",
      "0.8736769556999207\n",
      "0.1736360788345337\n",
      "0.8736748099327087\n",
      "0.9848597645759583\n",
      "0.1736360788345337\n",
      "0.9848597645759583\n",
      "0.5586779117584229\n",
      "0.6583579778671265\n",
      "0.5586779117584229\n",
      "0.8623551726341248\n",
      "0.6583552956581116\n",
      "0.8623551726341248\n",
      "0.9742223024368286\n",
      "0.7739973068237305\n",
      "0.9742207527160645\n",
      "0.7720776796340942\n",
      "0.7739999294281006\n",
      "0.7720776796340942\n",
      "5.120851369611046e-07\n",
      "0.33144378662109375\n",
      "5.120851369611046e-07\n",
      "3.271146852057427e-05\n",
      "0.33144378662109375\n",
      "3.271146852057427e-05\n",
      "6.36798418440776e-08\n",
      "0.73274827003479\n",
      "6.36798418440776e-08\n",
      "1.3617187505587935e-05\n",
      "0.73274827003479\n",
      "1.3617158401757479e-05\n",
      "5.7502784756024994e-08\n",
      "0.39715903997421265\n",
      "5.7502784756024994e-08\n",
      "3.345140066812746e-05\n",
      "0.39715903997421265\n",
      "3.345140066812746e-05\n",
      "6.081901204879614e-08\n",
      "0.42133909463882446\n",
      "6.081916836819801e-08\n",
      "5.7653702242532745e-05\n",
      "0.4213393032550812\n",
      "5.7653702242532745e-05\n",
      "6.46827018613294e-08\n",
      "0.46063974499702454\n",
      "6.46827018613294e-08\n",
      "5.832630267832428e-05\n",
      "0.4606364965438843\n",
      "5.8325960708316416e-05\n",
      "5.646451839425026e-08\n",
      "0.06316526234149933\n",
      "5.646436918027575e-08\n",
      "3.3753435673133936e-06\n",
      "0.06316526234149933\n",
      "3.3753285606508143e-06\n",
      "2.103855649693287e-07\n",
      "0.04208707436919212\n",
      "2.1038661657257762e-07\n",
      "3.431546065257862e-05\n",
      "0.04208707436919212\n",
      "3.431532240938395e-05\n",
      "2.6370884143034345e-07\n",
      "0.02954874373972416\n",
      "2.6370884143034345e-07\n",
      "5.316596798365936e-05\n",
      "0.029548456892371178\n",
      "5.316596798365936e-05\n",
      "4.460501372705039e-07\n",
      "0.07415667176246643\n",
      "4.460479772205872e-07\n",
      "3.214309981558472e-05\n",
      "0.07415593415498734\n",
      "3.214293974451721e-05\n",
      "3.089451183768688e-07\n",
      "0.07219473272562027\n",
      "3.0894435099071416e-07\n",
      "2.1660396669176407e-05\n",
      "0.0721961259841919\n",
      "2.1660396669176407e-05\n",
      "0.7274339199066162\n",
      "0.31984612345695496\n",
      "0.7274380326271057\n",
      "0.5702618956565857\n",
      "0.31984904408454895\n",
      "0.5702618956565857\n",
      "0.20343530178070068\n",
      "0.2918044626712799\n",
      "0.20343734323978424\n",
      "0.3323736786842346\n",
      "0.29180678725242615\n",
      "0.3323736786842346\n",
      "0.24552293121814728\n",
      "0.8052059412002563\n",
      "0.2455206662416458\n",
      "0.45463958382606506\n",
      "0.8052019476890564\n",
      "0.45463958382606506\n",
      "0.4152620732784271\n",
      "0.8967775702476501\n",
      "0.41526544094085693\n",
      "0.7098429203033447\n",
      "0.8967775702476501\n",
      "0.7098472118377686\n",
      "0.9883046746253967\n",
      "0.2553718686103821\n",
      "0.9883046746253967\n",
      "0.5155013203620911\n",
      "0.2553718686103821\n",
      "0.5154989957809448\n",
      "0.3272525370121002\n",
      "0.21852627396583557\n",
      "0.32725271582603455\n",
      "0.1070389375090599\n",
      "0.21852627396583557\n",
      "0.10703972727060318\n",
      "0.04197331890463829\n",
      "0.08419302850961685\n",
      "0.04197289049625397\n",
      "0.3596690595149994\n",
      "0.08419227600097656\n",
      "0.3596690595149994\n",
      "0.008178891614079475\n",
      "0.14704088866710663\n",
      "0.008178817108273506\n",
      "0.7442960739135742\n",
      "0.14704321324825287\n",
      "0.7443002462387085\n",
      "0.006968213710933924\n",
      "0.3069571852684021\n",
      "0.006968213710933924\n",
      "0.7390923500061035\n",
      "0.3069543242454529\n",
      "0.7390879392623901\n",
      "0.031943850219249725\n",
      "0.22772124409675598\n",
      "0.031943850219249725\n",
      "0.800382673740387\n",
      "0.22772343456745148\n",
      "0.8003825545310974\n",
      "0.04754773899912834\n",
      "0.5051044225692749\n",
      "0.04754773899912834\n",
      "0.6063470244407654\n",
      "0.5051078796386719\n",
      "0.6063513159751892\n",
      "0.02791425585746765\n",
      "0.44153130054473877\n",
      "0.02791406586766243\n",
      "0.716288149356842\n",
      "0.44153130054473877\n",
      "0.7162928581237793\n",
      "0.013327707536518574\n",
      "0.6914457082748413\n",
      "0.013327707536518574\n",
      "0.488654226064682\n",
      "0.6914458870887756\n",
      "0.488650381565094\n",
      "0.023735297843813896\n",
      "0.3082427978515625\n",
      "0.023735137656331062\n",
      "0.422983855009079\n",
      "0.3082472085952759\n",
      "0.422983855009079\n",
      "0.016530716791749\n",
      "0.8496420979499817\n",
      "0.016530698165297508\n",
      "0.3220418691635132\n",
      "0.8496384024620056\n",
      "0.3220418691635132\n",
      "0.005680573172867298\n",
      "0.14011217653751373\n",
      "0.005680569447577\n",
      "0.7368931174278259\n",
      "0.14011365175247192\n",
      "0.7368931174278259\n",
      "0.5713714957237244\n",
      "0.12004905194044113\n",
      "0.5713760256767273\n",
      "0.4572494626045227\n",
      "0.12005098164081573\n",
      "0.4572557806968689\n",
      "0.7305238842964172\n",
      "0.5313083529472351\n",
      "0.7305192351341248\n",
      "0.7131404876708984\n",
      "0.5313131809234619\n",
      "0.7131404876708984\n",
      "0.45532625913619995\n",
      "0.8091989159584045\n",
      "0.45532625913619995\n",
      "0.8157792687416077\n",
      "0.8091989159584045\n",
      "0.8157883882522583\n",
      "0.9898898601531982\n",
      "0.7883105874061584\n",
      "0.9898907542228699\n",
      "0.7650803923606873\n",
      "0.788305401802063\n",
      "0.7650803923606873\n",
      "0.0167913269251585\n",
      "0.30810627341270447\n",
      "0.016791246831417084\n",
      "0.17949028313159943\n",
      "0.30810627341270447\n",
      "0.17949028313159943\n",
      "0.02978292666375637\n",
      "0.2892043888568878\n",
      "0.02978292666375637\n",
      "0.05582540109753609\n",
      "0.2892058789730072\n",
      "0.05582447350025177\n",
      "0.030888644978404045\n",
      "0.4008153975009918\n",
      "0.030888784676790237\n",
      "0.04661048576235771\n",
      "0.40081557631492615\n",
      "0.046610765159130096\n",
      "0.04671156778931618\n",
      "0.5141934752464294\n",
      "0.04671179875731468\n",
      "0.09373673051595688\n",
      "0.5142022967338562\n",
      "0.09373617172241211\n",
      "0.04965416342020035\n",
      "0.8052323460578918\n",
      "0.049653954803943634\n",
      "0.039864037185907364\n",
      "0.8052323460578918\n",
      "0.03986383229494095\n",
      "0.6044272184371948\n",
      "0.5132173895835876\n",
      "0.604431688785553\n",
      "0.47182339429855347\n",
      "0.5132102966308594\n",
      "0.47182339429855347\n",
      "0.8955909013748169\n",
      "0.9813345670700073\n",
      "0.8955909013748169\n",
      "0.16544610261917114\n",
      "0.9813318848609924\n",
      "0.16544610261917114\n",
      "0.417562335729599\n",
      "0.8681616187095642\n",
      "0.417562335729599\n",
      "0.8465046286582947\n",
      "0.8681579828262329\n",
      "0.8465006351470947\n",
      "0.20194214582443237\n",
      "0.8934126496315002\n",
      "0.20194214582443237\n",
      "0.6874337196350098\n",
      "0.893409252166748\n",
      "0.6874337196350098\n",
      "0.1463647037744522\n",
      "0.9838181138038635\n",
      "0.14636260271072388\n",
      "0.5416818261146545\n",
      "0.9838168621063232\n",
      "0.5416818261146545\n",
      "4.5584460167447105e-05\n",
      "0.8447074890136719\n",
      "4.558450382319279e-05\n",
      "0.00046042699250392616\n",
      "0.844711422920227\n",
      "0.0004604289715643972\n",
      "1.6950920326053165e-05\n",
      "0.7118851542472839\n",
      "1.6950849385466427e-05\n",
      "0.00014275277499109507\n",
      "0.7118851542472839\n",
      "0.00014275277499109507\n",
      "1.5474093743250705e-05\n",
      "0.7171964645385742\n",
      "1.5474093743250705e-05\n",
      "8.527885802322999e-05\n",
      "0.717200517654419\n",
      "8.527820318704471e-05\n",
      "9.168470569420606e-06\n",
      "0.7463728189468384\n",
      "9.168490578304045e-06\n",
      "9.637082257540897e-05\n",
      "0.746372640132904\n",
      "9.637045877752826e-05\n",
      "5.1193997023801785e-06\n",
      "0.5110260844230652\n",
      "5.119366051076213e-06\n",
      "5.923250500927679e-05\n",
      "0.5110260844230652\n",
      "5.923250500927679e-05\n",
      "7.03782425262034e-05\n",
      "0.8754197359085083\n",
      "7.037797331577167e-05\n",
      "3.57052922481671e-05\n",
      "0.87542325258255\n",
      "3.570532862795517e-05\n",
      "9.149309335043654e-05\n",
      "0.9133830666542053\n",
      "9.149300603894517e-05\n",
      "0.00010172552720177919\n",
      "0.9133830666542053\n",
      "0.00010172514885198325\n",
      "1.343590429314645e-05\n",
      "0.023445826023817062\n",
      "1.343584790447494e-05\n",
      "0.0001476442557759583\n",
      "0.023445608094334602\n",
      "0.0001476442557759583\n",
      "1.13379028334748e-05\n",
      "0.04566720873117447\n",
      "1.1337806427036412e-05\n",
      "6.084201959311031e-05\n",
      "0.045667584985494614\n",
      "6.084225606173277e-05\n",
      "1.0309354365745094e-05\n",
      "0.1400136500597\n",
      "1.0309354365745094e-05\n",
      "3.763999120565131e-05\n",
      "0.14001235365867615\n",
      "3.7639914808096364e-05\n",
      "1.0190011607846827e-06\n",
      "3.8633002986898646e-05\n",
      "1.0189963859374984e-06\n",
      "8.098108139620308e-08\n",
      "3.863311940222047e-05\n",
      "8.098108139620308e-08\n",
      "6.551371711793763e-07\n",
      "1.6432950360467657e-05\n",
      "6.551371711793763e-07\n",
      "5.270158709436146e-08\n",
      "1.6432950360467657e-05\n",
      "5.2701448538527984e-08\n",
      "1.7987268563501857e-07\n",
      "0.00018330205057282\n",
      "1.798722450985224e-07\n",
      "4.123020858060045e-08\n",
      "0.00018330270540900528\n",
      "4.123010199919008e-08\n",
      "1.271516936185435e-07\n",
      "0.0002977528783958405\n",
      "1.2715136676888505e-07\n",
      "3.8490458820206186e-08\n",
      "0.0002977541880682111\n",
      "3.849055829618919e-08\n",
      "1.4506194645491632e-07\n",
      "0.0010074613383039832\n",
      "1.4506194645491632e-07\n",
      "4.2847524639455514e-08\n",
      "0.0010074572637677193\n",
      "4.2847524639455514e-08\n",
      "8.007835276657715e-06\n",
      "0.24121959507465363\n",
      "8.007800715859048e-06\n",
      "7.751243538223207e-05\n",
      "0.2412218451499939\n",
      "7.751243538223207e-05\n",
      "5.329016858013347e-06\n",
      "0.41082116961479187\n",
      "5.329040050128242e-06\n",
      "4.422062556841411e-05\n",
      "0.410817414522171\n",
      "4.422049460117705e-05\n",
      "1.2508411373346462e-06\n",
      "0.9735445976257324\n",
      "1.2508411373346462e-06\n",
      "1.5057622476888355e-05\n",
      "0.9735445976257324\n",
      "1.505771706433734e-05\n",
      "1.2339266959315864e-06\n",
      "0.9992964863777161\n",
      "1.2339324939603102e-06\n",
      "3.123285932815634e-05\n",
      "0.9992963075637817\n",
      "3.12330448650755e-05\n",
      "9.889556622511009e-07\n",
      "0.9828374981880188\n",
      "9.88958049674693e-07\n",
      "2.4097371351672336e-05\n",
      "0.9828374981880188\n",
      "2.409722401353065e-05\n",
      "5.407312073657522e-07\n",
      "0.1143934428691864\n",
      "5.407298999671184e-07\n",
      "1.8280249491908762e-07\n",
      "0.11439259350299835\n",
      "1.8280249491908762e-07\n",
      "1.188894955816977e-07\n",
      "0.44238972663879395\n",
      "1.1888919715374868e-07\n",
      "6.479321967844953e-08\n",
      "0.44239315390586853\n",
      "6.479338310327876e-08\n",
      "1.3235926132892928e-07\n",
      "0.6977962851524353\n",
      "1.3235926132892928e-07\n",
      "6.22305194042383e-08\n",
      "0.6977871656417847\n",
      "6.22305194042383e-08\n",
      "1.4364155731527717e-07\n",
      "0.815692126750946\n",
      "1.4364155731527717e-07\n",
      "5.758395360544455e-08\n",
      "0.8156877756118774\n",
      "5.758380439147004e-08\n",
      "1.5522104490628408e-07\n",
      "0.7280365824699402\n",
      "1.5522182650329341e-07\n",
      "5.8354839183039076e-08\n",
      "0.7280365824699402\n",
      "5.835468641635089e-08\n",
      "0.0028726498130708933\n",
      "0.673466145992279\n",
      "0.0028726309537887573\n",
      "0.2805785834789276\n",
      "0.6734704971313477\n",
      "0.28058120608329773\n",
      "0.9617421627044678\n",
      "0.35898569226264954\n",
      "0.9617441892623901\n",
      "0.24877145886421204\n",
      "0.3589891195297241\n",
      "0.24877282977104187\n",
      "0.054614707827568054\n",
      "0.5737545490264893\n",
      "0.054614707827568054\n",
      "0.9373138546943665\n",
      "0.5737545490264893\n",
      "0.9373108148574829\n",
      "0.028559517115354538\n",
      "0.8157432079315186\n",
      "0.028559517115354538\n",
      "0.974990963935852\n",
      "0.8157433867454529\n",
      "0.974990963935852\n",
      "0.02290397509932518\n",
      "0.9543495774269104\n",
      "0.022903665900230408\n",
      "0.45138072967529297\n",
      "0.9543495774269104\n",
      "0.45138072967529297\n",
      "3.975684421675396e-07\n",
      "0.8847086429595947\n",
      "3.975664810695889e-07\n",
      "4.072075626027072e-06\n",
      "0.8847017884254456\n",
      "4.072066531080054e-06\n",
      "1.2694340512098279e-06\n",
      "0.9859071373939514\n",
      "1.2694310953520471e-06\n",
      "4.402364993438823e-06\n",
      "0.9859082698822021\n",
      "4.402364993438823e-06\n",
      "3.940295698612317e-07\n",
      "0.9700080156326294\n",
      "3.940295698612317e-07\n",
      "6.601142104045721e-06\n",
      "0.9700063467025757\n",
      "6.601156201213598e-06\n",
      "1.7686093656266166e-07\n",
      "0.966035008430481\n",
      "1.7686137709915783e-07\n",
      "7.045307029329706e-06\n",
      "0.9660348892211914\n",
      "7.045322035992285e-06\n",
      "6.082250081362872e-08\n",
      "0.0781584158539772\n",
      "6.082234449422685e-08\n",
      "1.0455274605192244e-05\n",
      "0.0781589224934578\n",
      "1.0455297342559788e-05\n",
      "0.049802348017692566\n",
      "0.926646888256073\n",
      "0.04980190470814705\n",
      "0.256826788187027\n",
      "0.926646888256073\n",
      "0.2568241357803345\n",
      "0.042846761643886566\n",
      "0.5677570104598999\n",
      "0.04284672066569328\n",
      "0.49766501784324646\n",
      "0.5677653551101685\n",
      "0.49766501784324646\n",
      "0.04840511456131935\n",
      "0.7961511015892029\n",
      "0.04840511456131935\n",
      "0.3436448574066162\n",
      "0.7961511015892029\n",
      "0.3436475396156311\n",
      "0.04436098039150238\n",
      "0.7549586296081543\n",
      "0.044360119849443436\n",
      "0.43570584058761597\n",
      "0.7549542188644409\n",
      "0.43570923805236816\n",
      "0.06047948822379112\n",
      "0.850582480430603\n",
      "0.06047948822379112\n",
      "0.3217496871948242\n",
      "0.8505865335464478\n",
      "0.3217496871948242\n",
      "0.611773669719696\n",
      "0.048531726002693176\n",
      "0.6117696166038513\n",
      "0.6181275248527527\n",
      "0.048531342297792435\n",
      "0.6181315779685974\n",
      "0.21599890291690826\n",
      "0.05698665603995323\n",
      "0.2160007357597351\n",
      "0.5036227107048035\n",
      "0.05698758363723755\n",
      "0.5036227107048035\n",
      "0.999943733215332\n",
      "0.07397886365652084\n",
      "0.999943733215332\n",
      "0.3198600709438324\n",
      "0.07397832721471786\n",
      "0.319857656955719\n",
      "0.9447887539863586\n",
      "0.9876766204833984\n",
      "0.9447911977767944\n",
      "0.7037036418914795\n",
      "0.9876756072044373\n",
      "0.7037036418914795\n",
      "0.7900848388671875\n",
      "0.8285790085792542\n",
      "0.7900848388671875\n",
      "0.9043542146682739\n",
      "0.8285744786262512\n",
      "0.9043576121330261\n",
      "0.7809836268424988\n",
      "0.42012453079223633\n",
      "0.7809886336326599\n",
      "0.721481204032898\n",
      "0.42012453079223633\n",
      "0.7214909195899963\n",
      "0.24536368250846863\n",
      "0.666928231716156\n",
      "0.24536368250846863\n",
      "0.28479164838790894\n",
      "0.666928231716156\n",
      "0.28479674458503723\n",
      "0.8992268443107605\n",
      "0.8358159065246582\n",
      "0.8992230892181396\n",
      "0.5946546196937561\n",
      "0.8358159065246582\n",
      "0.5946503281593323\n",
      "0.7526934146881104\n",
      "0.9843728542327881\n",
      "0.752687931060791\n",
      "0.7660616040229797\n",
      "0.9843728542327881\n",
      "0.7660616040229797\n",
      "0.681251049041748\n",
      "0.5863784551620483\n",
      "0.6812563538551331\n",
      "0.48545947670936584\n",
      "0.5863784551620483\n",
      "0.48545601963996887\n",
      "0.48589396476745605\n",
      "0.14005239307880402\n",
      "0.48588991165161133\n",
      "0.6260013580322266\n",
      "0.14005334675312042\n",
      "0.6260013580322266\n",
      "0.6077375411987305\n",
      "0.02178981527686119\n",
      "0.607732892036438\n",
      "0.7376022338867188\n",
      "0.02178993821144104\n",
      "0.7375937104225159\n",
      "0.6849232912063599\n",
      "0.08457481116056442\n",
      "0.6849187016487122\n",
      "0.8158894777297974\n",
      "0.0845741331577301\n",
      "0.8158854246139526\n",
      "0.6272392272949219\n",
      "0.11076187342405319\n",
      "0.6272392272949219\n",
      "0.8033972382545471\n",
      "0.1107601448893547\n",
      "0.8033972382545471\n",
      "0.757853090763092\n",
      "0.17315791547298431\n",
      "0.757853090763092\n",
      "0.708247184753418\n",
      "0.17315655946731567\n",
      "0.7082514762878418\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "main_path = '/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/'\n",
    "verbose = False\n",
    "# main_path = '/home/paul/thesis/dev/SAY_sf_prediction_v3/scrambled_dataset/'\n",
    "file_list = Path(main_path).glob('*batch?.csv')\n",
    "for file in file_list:\n",
    "    if verbose is True:\n",
    "        print(file)\n",
    "    df = pd.read_csv(file)\n",
    "    # ,ave to a copy of df, then perform Fisher's r to z transformation on Pearson scores\n",
    "    df_z = df.copy()\n",
    "    for i in range(1, 6):\n",
    "        df_z[str(i)] = np.arctanh(df_z[str(i)])\n",
    "    # print(df_z)\n",
    "    if verbose is True:\n",
    "        print(file.stem)\n",
    "    # compare difference in score between Recon methods for each walk length column\n",
    "    for i in range(1, 6):\n",
    "        if verbose is True:\n",
    "            print('Walk Length: '+str(i))\n",
    "        # get unique values of Recon column\n",
    "        recon_list = df['Recon'].unique()\n",
    "        df_stats_all = pd.DataFrame()\n",
    "        df_stats = pd.DataFrame()\n",
    "        # loop through each unique value of Recon column\n",
    "        for recon in recon_list:\n",
    "            if verbose is True:\n",
    "                print(recon)\n",
    "            # combine statistics from each Recon method into dataframe\n",
    "            df_stats = pd.DataFrame({'Recon': recon_list, 'Mean': df[df['Recon'] == str(recon)][str(i)].mean(), 'Stdev': df[df['Recon'] == str(recon)][str(i)].std(\n",
    "            ), 'Median': df[df['Recon'] == str(recon)][str(i)].median(), 'IQR': df[df['Recon'] == str(recon)][str(i)].quantile(q=0.75)-df[df['Recon'] == str(recon)][str(i)].quantile(q=0.25)})\n",
    "            # combine df_stats from each Recon method into dataframe\n",
    "            df_stats_all = pd.concat([df_stats, df_stats_all], axis=0)\n",
    "        # print(df_stats_all)\n",
    "        # save dataframe to csv\n",
    "        df_stats_all.to_csv(main_path+'/stats/'+file.stem +\n",
    "                            '_walk_length_'+str(i)+'_stats.csv', index=False)\n",
    "        # calculate p-value for difference in score between Recon methods in recon_list, with comparisons between each pair of Recon methods, save all statistics and p-values to csv\n",
    "        df_z_ttest_rel_results = pd.DataFrame()\n",
    "        df_z_shapiro_wilk_results = pd.DataFrame()\n",
    "        df_z_wilcoxon_results = pd.DataFrame()\n",
    "        for recon in recon_list:\n",
    "            for recon2 in recon_list:\n",
    "                if recon != recon2:\n",
    "                    if verbose is True:\n",
    "                        print(recon)\n",
    "                        print(recon2)\n",
    "                    # calculate t-test on z-scores, get t-statistic and p-value and effect size, means\n",
    "                    ttest_rel_z_score = paired_ttest(df_z[df_z['Recon'] == str(\n",
    "                        recon)][str(i)], df_z[df_z['Recon'] == str(recon2)][str(i)], alternative='less')\n",
    "                    # calculate shapiro-wilk test on z-scores, get W-statistic and p-value\n",
    "                    # get array of df_z values for recon and recon2\n",
    "                    recon_1_z_scores = np.array(df_z[df_z['Recon'] == str(recon)][str(i)])\n",
    "                    recon_2_z_scores = np.array(df_z[df_z['Recon'] == str(recon2)][str(i)])\n",
    "                    # calculate differences between arrays of recon and recon2 z-scores\n",
    "                    differences = recon_1_z_scores - recon_2_z_scores\n",
    "                    shapiro_wilk_w, shapiro_wilk_p = stats.shapiro(differences)\n",
    "                    if verbose:\n",
    "                        print(shapiro_wilk_p)\n",
    "                    # calculate wilcoxon test on z-scores, get test statistic and p-value and effect size, medians\n",
    "                    wilcoxon_results = wilcoxon_test(df_z[df_z['Recon'] == str(\n",
    "                        recon)][str(i)], df_z[df_z['Recon'] == str(recon2)][str(i)], alternative='less')\n",
    "                    # combine stats into dataframe\n",
    "                    df_z_ttest_rel_results = pd.concat([df_z_ttest_rel_results, pd.DataFrame({'Recon 1': recon, 'Recon 2': recon2, 'T-statistic Paired T-test': ttest_rel_z_score[0],\n",
    "                                                                                                'p-value Paired T-test': ttest_rel_z_score[1], 'Effect Size d': ttest_rel_z_score[2],\n",
    "                                                                                                'Mean 1': ttest_rel_z_score[3], 'Mean 2': ttest_rel_z_score[4]}, index=[0])], axis=0)\n",
    "                    df_z_shapiro_wilk_results = pd.concat([df_z_shapiro_wilk_results, pd.DataFrame({'Recon 1': recon, 'Recon 2': recon2, 'W-statistic Shapiro-Wilk test': shapiro_wilk_w,\n",
    "                                                                                                    'p-value Shapiro-Wilk test': shapiro_wilk_p}, index=[0])], axis=0)\n",
    "                    df_z_wilcoxon_results = pd.concat([df_z_wilcoxon_results, pd.DataFrame({'Recon 1': recon, 'Recon 2': recon2, 'Test statistic Wilcoxon Signed Rank Test': wilcoxon_results[0],\n",
    "                                                                                            'p-value Wilcoxon Signed Rank Test': wilcoxon_results[1], 'Effect Size r': wilcoxon_results[2],\n",
    "                                                                                            'Median 1': wilcoxon_results[3], 'Median 2': wilcoxon_results[4]}, index=[0])], axis=0)\n",
    "        # print('T-test rel z-score results')\n",
    "        # print(df_z_ttest_rel_results)\n",
    "        # print('Shapiro-Wilk z-score results')\n",
    "        # print(df_z_shapiro_wilk_results)\n",
    "        # print('Wilcoxon z-score results')\n",
    "        # print(df_z_wilcoxon_results)\n",
    "\n",
    "        # save dataframe to csv\n",
    "        df_z_ttest_rel_results.to_csv(\n",
    "            main_path+'/stats/'+file.stem+'_walk_length_'+str(i)+'_z_score_ttest_rel_results.csv', index=False)\n",
    "        df_z_shapiro_wilk_results.to_csv(\n",
    "            main_path+'/stats/'+file.stem+'_walk_length_'+str(i)+'_shapiro_wilk_results.csv', index=False)\n",
    "        df_z_wilcoxon_results.to_csv(\n",
    "            main_path+'/stats/'+file.stem+'_walk_length_'+str(i)+'_wilcoxon_results.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Box Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/volume_weighted_all_percent_batch16.csv\n",
      "volume_weighted_all_percent_batch16\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/count_all_percent_batch11.csv\n",
      "count_all_percent_batch11\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/count_all_percent_batch12.csv\n",
      "count_all_percent_batch12\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/volume_weighted_all_percent_batch13.csv\n",
      "volume_weighted_all_percent_batch13\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/volume_weighted_all_percent_batch17.csv\n",
      "volume_weighted_all_percent_batch17\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/count_all_percent_batch15.csv\n",
      "count_all_percent_batch15\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/count_all_percent_batch18.csv\n",
      "count_all_percent_batch18\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/volume_weighted_all_percent_batch15.csv\n",
      "volume_weighted_all_percent_batch15\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/count_all_percent_batch19.csv\n",
      "count_all_percent_batch19\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/count_all_percent_batch14.csv\n",
      "count_all_percent_batch14\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/count_all_percent_batch17.csv\n",
      "count_all_percent_batch17\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/volume_weighted_all_percent_batch18.csv\n",
      "volume_weighted_all_percent_batch18\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/volume_weighted_all_percent_batch11.csv\n",
      "volume_weighted_all_percent_batch11\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/count_all_percent_batch13.csv\n",
      "count_all_percent_batch13\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/volume_weighted_all_percent_batch10.csv\n",
      "volume_weighted_all_percent_batch10\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/volume_weighted_all_percent_batch14.csv\n",
      "volume_weighted_all_percent_batch14\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/volume_weighted_all_percent_batch19.csv\n",
      "volume_weighted_all_percent_batch19\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/count_all_percent_batch10.csv\n",
      "count_all_percent_batch10\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/count_all_percent_batch16.csv\n",
      "count_all_percent_batch16\n",
      "/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/volume_weighted_all_percent_batch12.csv\n",
      "volume_weighted_all_percent_batch12\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "main_path = '/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/'\n",
    "\n",
    "file_list = Path(main_path).glob('*batch??.csv')\n",
    "for file in file_list:\n",
    "    print(file)\n",
    "    df = pd.read_csv(file)\n",
    "    print(file.stem)\n",
    "    # melt data for boxplot\n",
    "    dd=pd.melt(df,id_vars=['Recon'],value_vars=['1','2','3','4','5'],var_name='Walk Length')\n",
    "    # seaborn boxplot with hue based on recon method\n",
    "    sns.boxplot(x='Walk Length',y='value',data=dd,hue='Recon')\n",
    "    # plt.show()\n",
    "    plt.ylabel('Pearson Score')\n",
    "    # save figure\n",
    "    plt.savefig(main_path+'/plots/'+file.stem+'_box_plot.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_619693/2977612436.py:17: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dm.mean().to_csv(main_path+'/stats/walk_4_DTI_msmt_volume_weighted_paired_ttest_results_mean.csv')\n",
      "/tmp/ipykernel_619693/2977612436.py:18: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dm.std().to_csv(main_path+'/stats/walk_4_DTI_msmt_volume_weighted_paired_ttest_results_std.csv')\n",
      "/tmp/ipykernel_619693/2977612436.py:27: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_gm.mean().to_csv(main_path+'/stats/walk_4_GQI_msmt_volume_weighted_paired_ttest_results_mean.csv')\n",
      "/tmp/ipykernel_619693/2977612436.py:28: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_gm.std().to_csv(main_path+'/stats/walk_4_GQI_msmt_volume_weighted_paired_ttest_results_std.csv')\n",
      "/tmp/ipykernel_619693/2977612436.py:37: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dq.mean().to_csv(main_path+'/stats/walk_4_DTI_GQI_volume_weighted_paired_ttest_results_mean.csv')\n",
      "/tmp/ipykernel_619693/2977612436.py:38: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dq.std().to_csv(main_path+'/stats/walk_4_DTI_GQI_volume_weighted_paired_ttest_results_std.csv')\n",
      "/tmp/ipykernel_619693/2977612436.py:45: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_vol_ttest = pd.concat([df_dm.mean(),df_dm.std(),df_gm.mean(),df_gm.std(),df_dq.mean(),df_dq.std()],axis=1)\n"
     ]
    }
   ],
   "source": [
    "# read in z-score paired t-test results from all batches in main_path/stats with walk length 4\n",
    "verbose = False\n",
    "main_path = '/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/'\n",
    "# main_path = '/home/paul/thesis/dev/SAY_sf_prediction_v3/scrambled_dataset/'\n",
    "file_list = Path(main_path+'/stats').glob('volume_*_walk_length_4_z_score_ttest_rel_results.csv')\n",
    "df_ii = pd.DataFrame()\n",
    "for file in file_list:\n",
    "    if verbose:\n",
    "        print(file)\n",
    "    df_ii = pd.concat([df,pd.read_csv(file)],axis=0)\n",
    "\n",
    "df_dm = get_df_int(df=df_ii, recon1='DTI Node Volume Weighted Streamline Count', recon2='MSMT CSD SIFT2 Node Volume Weighted Streamline Count', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_dm)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_dm.mean().to_csv(main_path+'/stats/walk_4_DTI_msmt_volume_weighted_paired_ttest_results_mean.csv')\n",
    "df_dm.std().to_csv(main_path+'/stats/walk_4_DTI_msmt_volume_weighted_paired_ttest_results_std.csv')\n",
    "df_dm.max().to_csv(main_path+'/stats/walk_4_DTI_msmt_volume_weighted_paired_ttest_results_max.csv')\n",
    "df_dm.min().to_csv(main_path+'/stats/walk_4_DTI_msmt_volume_weighted_paired_ttest_results_min.csv')\n",
    "\n",
    "df_gm = get_df_int(df=df_ii, recon1='GQI Node Volume Weighted Streamline Count', recon2='MSMT CSD SIFT2 Node Volume Weighted Streamline Count', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_gm)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_gm.mean().to_csv(main_path+'/stats/walk_4_GQI_msmt_volume_weighted_paired_ttest_results_mean.csv')\n",
    "df_gm.std().to_csv(main_path+'/stats/walk_4_GQI_msmt_volume_weighted_paired_ttest_results_std.csv')\n",
    "df_gm.max().to_csv(main_path+'/stats/walk_4_GQI_msmt_volume_weighted_paired_ttest_results_max.csv')\n",
    "df_gm.min().to_csv(main_path+'/stats/walk_4_GQI_msmt_volume_weighted_paired_ttest_results_min.csv')\n",
    "\n",
    "df_dq = get_df_int(df=df_ii, recon1='DTI Node Volume Weighted Streamline Count', recon2='GQI Node Volume Weighted Streamline Count', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_dq)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_dq.mean().to_csv(main_path+'/stats/walk_4_DTI_GQI_volume_weighted_paired_ttest_results_mean.csv')\n",
    "df_dq.std().to_csv(main_path+'/stats/walk_4_DTI_GQI_volume_weighted_paired_ttest_results_std.csv')\n",
    "df_dq.max().to_csv(main_path+'/stats/walk_4_DTI_GQI_volume_weighted_paired_ttest_results_max.csv')\n",
    "df_dq.min().to_csv(main_path+'/stats/walk_4_DTI_GQI_volume_weighted_paired_ttest_results_min.csv')\n",
    "\n",
    "# read in z-score paired t-test results from all batches in main_path/stats with walk length 4\n",
    "verbose = False\n",
    "df_vol_ttest = pd.DataFrame()\n",
    "df_vol_ttest = pd.concat([df_dm.mean(),df_dm.std(),df_gm.mean(),df_gm.std(),df_dq.mean(),df_dq.std()],axis=1)\n",
    "df_vol_ttest.columns = ['DTI_MSMT_mean','DTI_MSMT_std','GQI_MSMT_mean','GQI_MSMT_std','DTI_GQI_mean','DTI_GQI_std']\n",
    "df_vol_ttest.to_csv(main_path+'/stats/walk_4_volume_weighted_paired_ttest_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_619693/127232398.py:17: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dm.mean().to_csv(main_path+'/stats/walk_4_DTI_msmt_volume_weighted_wilcoxon_results_mean.csv')\n",
      "/tmp/ipykernel_619693/127232398.py:18: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dm.std().to_csv(main_path+'/stats/walk_4_DTI_msmt_volume_weighted_wilcoxon_results_std.csv')\n",
      "/tmp/ipykernel_619693/127232398.py:27: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_gm.mean().to_csv(main_path+'/stats/walk_4_GQI_msmt_volume_weighted_wilcoxon_results_mean.csv')\n",
      "/tmp/ipykernel_619693/127232398.py:28: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_gm.std().to_csv(main_path+'/stats/walk_4_GQI_msmt_volume_weighted_wilcoxon_results_std.csv')\n",
      "/tmp/ipykernel_619693/127232398.py:37: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dq.mean().to_csv(main_path+'/stats/walk_4_DTI_GQI_volume_weighted_wilcoxon_results_mean.csv')\n",
      "/tmp/ipykernel_619693/127232398.py:38: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dq.std().to_csv(main_path+'/stats/walk_4_DTI_GQI_volume_weighted_wilcoxon_results_std.csv')\n",
      "/tmp/ipykernel_619693/127232398.py:45: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_vol_wil = pd.concat([df_dm.mean(),df_dm.std(),df_gm.mean(),df_gm.std(),df_dq.mean(),df_dq.std()],axis=1)\n"
     ]
    }
   ],
   "source": [
    "# read in z-score wilcoxon signed rank test results from all batches in main_path/stats with walk length 4\n",
    "verbose = False\n",
    "main_path = '/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/'\n",
    "# main_path = '/home/paul/thesis/dev/SAY_sf_prediction_v3/scrambled_dataset/'\n",
    "file_list = Path(main_path+'/stats').glob('volume_*_walk_length_4_wilcoxon_results.csv')\n",
    "df_ii = pd.DataFrame()\n",
    "for file in file_list:\n",
    "    if verbose:\n",
    "        print(file)\n",
    "    df_ii = pd.concat([df,pd.read_csv(file)],axis=0)\n",
    "\n",
    "df_dm = get_df_int(df=df_ii, recon1='DTI Node Volume Weighted Streamline Count', recon2='MSMT CSD SIFT2 Node Volume Weighted Streamline Count', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_dm)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_dm.mean().to_csv(main_path+'/stats/walk_4_DTI_msmt_volume_weighted_wilcoxon_results_mean.csv')\n",
    "df_dm.std().to_csv(main_path+'/stats/walk_4_DTI_msmt_volume_weighted_wilcoxon_results_std.csv')\n",
    "df_dm.max().to_csv(main_path+'/stats/walk_4_DTI_msmt_volume_weighted_wilcoxon_results_max.csv')\n",
    "df_dm.min().to_csv(main_path+'/stats/walk_4_DTI_msmt_volume_weighted_wilcoxon_results_min.csv')\n",
    "\n",
    "df_gm = get_df_int(df=df_ii, recon1='GQI Node Volume Weighted Streamline Count', recon2='MSMT CSD SIFT2 Node Volume Weighted Streamline Count', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_gm)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_gm.mean().to_csv(main_path+'/stats/walk_4_GQI_msmt_volume_weighted_wilcoxon_results_mean.csv')\n",
    "df_gm.std().to_csv(main_path+'/stats/walk_4_GQI_msmt_volume_weighted_wilcoxon_results_std.csv')\n",
    "df_gm.max().to_csv(main_path+'/stats/walk_4_GQI_msmt_volume_weighted_wilcoxon_results_max.csv')\n",
    "df_gm.min().to_csv(main_path+'/stats/walk_4_GQI_msmt_volume_weighted_wilcoxon_results_min.csv')\n",
    "\n",
    "df_dq = get_df_int(df=df_ii, recon1='DTI Node Volume Weighted Streamline Count', recon2='GQI Node Volume Weighted Streamline Count', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_dq)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_dq.mean().to_csv(main_path+'/stats/walk_4_DTI_GQI_volume_weighted_wilcoxon_results_mean.csv')\n",
    "df_dq.std().to_csv(main_path+'/stats/walk_4_DTI_GQI_volume_weighted_wilcoxon_results_std.csv')\n",
    "df_dq.max().to_csv(main_path+'/stats/walk_4_DTI_GQI_volume_weighted_wilcoxon_results_max.csv')\n",
    "df_dq.min().to_csv(main_path+'/stats/walk_4_DTI_GQI_volume_weighted_wilcoxon_results_min.csv')\n",
    "\n",
    "# combine all volume weighted wilcoxon signed rank test results at walk length 4\n",
    "verbose = False\n",
    "df_vol_wil = pd.DataFrame()\n",
    "df_vol_wil = pd.concat([df_dm.mean(),df_dm.std(),df_gm.mean(),df_gm.std(),df_dq.mean(),df_dq.std()],axis=1)\n",
    "df_vol_wil.columns = ['DTI_MSMT_mean','DTI_MSMT_std','GQI_MSMT_mean','GQI_MSMT_std','DTI_GQI_mean','DTI_GQI_std']\n",
    "df_vol_wil.to_csv(main_path+'/stats/walk_4_volume_weighted_wilcoxon_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_619693/4074295172.py:17: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dm.mean().to_csv(main_path+'/stats/walk_4_DTI_msmt_count_paired_ttest_results_mean.csv')\n",
      "/tmp/ipykernel_619693/4074295172.py:18: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dm.std().to_csv(main_path+'/stats/walk_4_DTI_msmt_count_paired_ttest_results_std.csv')\n",
      "/tmp/ipykernel_619693/4074295172.py:27: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_gm.mean().to_csv(main_path+'/stats/walk_4_GQI_msmt_count_paired_ttest_results_mean.csv')\n",
      "/tmp/ipykernel_619693/4074295172.py:28: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_gm.std().to_csv(main_path+'/stats/walk_4_GQI_msmt_count_paired_ttest_results_std.csv')\n",
      "/tmp/ipykernel_619693/4074295172.py:37: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dq.mean().to_csv(main_path+'/stats/walk_4_DTI_GQI_count_paired_ttest_results_mean.csv')\n",
      "/tmp/ipykernel_619693/4074295172.py:38: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dq.std().to_csv(main_path+'/stats/walk_4_DTI_GQI_count_paired_ttest_results_std.csv')\n",
      "/tmp/ipykernel_619693/4074295172.py:46: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_count_ttest = pd.concat([df_dm.mean(),df_dm.std(),df_gm.mean(),df_gm.std(),df_dq.mean(),df_dq.std()],axis=1)\n"
     ]
    }
   ],
   "source": [
    "# read in z-score paired t-test results from all batches in main_path/stats with walk length 4\n",
    "verbose = False\n",
    "main_path = '/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/'\n",
    "# main_path = '/home/paul/thesis/dev/SAY_sf_prediction_v3/scrambled_dataset/'\n",
    "file_list = Path(main_path+'/stats').glob('count_*_walk_length_4_z_score_ttest_rel_results.csv')\n",
    "df_ii = pd.DataFrame()\n",
    "for file in file_list:\n",
    "    if verbose:\n",
    "        print(file)\n",
    "    df_ii = pd.concat([df,pd.read_csv(file)],axis=0)\n",
    "\n",
    "df_dm = get_df_int(df=df_ii, recon1='DTI Streamline Count', recon2='MSMT CSD SIFT2 Streamline Count', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_dm)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_dm.mean().to_csv(main_path+'/stats/walk_4_DTI_msmt_count_paired_ttest_results_mean.csv')\n",
    "df_dm.std().to_csv(main_path+'/stats/walk_4_DTI_msmt_count_paired_ttest_results_std.csv')\n",
    "df_dm.max().to_csv(main_path+'/stats/walk_4_DTI_msmt_count_paired_ttest_results_max.csv')\n",
    "df_dm.min().to_csv(main_path+'/stats/walk_4_DTI_msmt_count_paired_ttest_results_min.csv')\n",
    "\n",
    "df_gm = get_df_int(df=df_ii, recon1='GQI Streamline Count', recon2='MSMT CSD SIFT2 Streamline Count', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_gm)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_gm.mean().to_csv(main_path+'/stats/walk_4_GQI_msmt_count_paired_ttest_results_mean.csv')\n",
    "df_gm.std().to_csv(main_path+'/stats/walk_4_GQI_msmt_count_paired_ttest_results_std.csv')\n",
    "df_gm.max().to_csv(main_path+'/stats/walk_4_GQI_msmt_count_paired_ttest_results_max.csv')\n",
    "df_gm.min().to_csv(main_path+'/stats/walk_4_GQI_msmt_count_paired_ttest_results_min.csv')\n",
    "\n",
    "df_dq = get_df_int(df=df_ii, recon1='DTI Streamline Count', recon2='GQI Streamline Count', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_dq)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_dq.mean().to_csv(main_path+'/stats/walk_4_DTI_GQI_count_paired_ttest_results_mean.csv')\n",
    "df_dq.std().to_csv(main_path+'/stats/walk_4_DTI_GQI_count_paired_ttest_results_std.csv')\n",
    "df_dq.max().to_csv(main_path+'/stats/walk_4_DTI_GQI_count_paired_ttest_results_max.csv')\n",
    "df_dq.min().to_csv(main_path+'/stats/walk_4_DTI_GQI_count_paired_ttest_results_min.csv')\n",
    "\n",
    "\n",
    "# combine all count t-test results at walk length 4\n",
    "verbose = False\n",
    "df_count_ttest = pd.DataFrame()\n",
    "df_count_ttest = pd.concat([df_dm.mean(),df_dm.std(),df_gm.mean(),df_gm.std(),df_dq.mean(),df_dq.std()],axis=1)\n",
    "df_count_ttest.columns = ['DTI_MSMT_mean','DTI_MSMT_std','GQI_MSMT_mean','GQI_MSMT_std','DTI_GQI_mean','DTI_GQI_std']\n",
    "df_count_ttest.to_csv(main_path+'/stats/walk_4_count_paired_ttest_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_619693/1331690065.py:17: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dm.mean().to_csv(main_path+'/stats/walk_4_DTI_msmt_count_wilcoxon_results_mean.csv')\n",
      "/tmp/ipykernel_619693/1331690065.py:18: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dm.std().to_csv(main_path+'/stats/walk_4_DTI_msmt_count_wilcoxon_results_std.csv')\n",
      "/tmp/ipykernel_619693/1331690065.py:27: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_gm.mean().to_csv(main_path+'/stats/walk_4_GQI_msmt_count_wilcoxon_results_mean.csv')\n",
      "/tmp/ipykernel_619693/1331690065.py:28: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_gm.std().to_csv(main_path+'/stats/walk_4_GQI_msmt_count_wilcoxon_results_std.csv')\n",
      "/tmp/ipykernel_619693/1331690065.py:37: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dq.mean().to_csv(main_path+'/stats/walk_4_DTI_GQI_count_wilcoxon_results_mean.csv')\n",
      "/tmp/ipykernel_619693/1331690065.py:38: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_dq.std().to_csv(main_path+'/stats/walk_4_DTI_GQI_count_wilcoxon_results_std.csv')\n",
      "/tmp/ipykernel_619693/1331690065.py:45: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_count_wil = pd.concat([df_dm.mean(),df_dm.std(),df_gm.mean(),df_gm.std(),df_dq.mean(),df_dq.std()],axis=1)\n"
     ]
    }
   ],
   "source": [
    "# read in z-score wilcoxon signed rank test results from all batches in main_path/stats with walk length 4\n",
    "verbose = False\n",
    "main_path = '/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/'\n",
    "# main_path = '/home/paul/thesis/dev/SAY_sf_prediction_v3/scrambled_dataset/'\n",
    "file_list = Path(main_path+'/stats').glob('count_*_walk_length_4_wilcoxon_results.csv')\n",
    "df_ii = pd.DataFrame()\n",
    "for file in file_list:\n",
    "    if verbose:\n",
    "        print(file)\n",
    "    df_ii = pd.concat([df,pd.read_csv(file)],axis=0)\n",
    "\n",
    "df_dm = get_df_int(df=df_ii, recon1='DTI Streamline Count', recon2='MSMT CSD SIFT2 Streamline Count', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_dm)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_dm.mean().to_csv(main_path+'/stats/walk_4_DTI_msmt_count_wilcoxon_results_mean.csv')\n",
    "df_dm.std().to_csv(main_path+'/stats/walk_4_DTI_msmt_count_wilcoxon_results_std.csv')\n",
    "df_dm.max().to_csv(main_path+'/stats/walk_4_DTI_msmt_count_wilcoxon_results_max.csv')\n",
    "df_dm.min().to_csv(main_path+'/stats/walk_4_DTI_msmt_count_wilcoxon_results_min.csv')\n",
    "\n",
    "df_gm = get_df_int(df=df_ii, recon1='GQI Streamline Count', recon2='MSMT CSD SIFT2 Streamline Count', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_gm)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_gm.mean().to_csv(main_path+'/stats/walk_4_GQI_msmt_count_wilcoxon_results_mean.csv')\n",
    "df_gm.std().to_csv(main_path+'/stats/walk_4_GQI_msmt_count_wilcoxon_results_std.csv')\n",
    "df_gm.max().to_csv(main_path+'/stats/walk_4_GQI_msmt_count_wilcoxon_results_max.csv')\n",
    "df_gm.min().to_csv(main_path+'/stats/walk_4_GQI_msmt_count_wilcoxon_results_min.csv')\n",
    "\n",
    "df_dq = get_df_int(df=df_ii, recon1='DTI Streamline Count', recon2='GQI Streamline Count', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_dq)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_dq.mean().to_csv(main_path+'/stats/walk_4_DTI_GQI_count_wilcoxon_results_mean.csv')\n",
    "df_dq.std().to_csv(main_path+'/stats/walk_4_DTI_GQI_count_wilcoxon_results_std.csv')\n",
    "df_dq.max().to_csv(main_path+'/stats/walk_4_DTI_GQI_count_wilcoxon_results_max.csv')\n",
    "df_dq.min().to_csv(main_path+'/stats/walk_4_DTI_GQI_count_wilcoxon_results_min.csv')\n",
    "\n",
    "# combine all volume weighted wilcoxon signed rank test results at walk length 4\n",
    "verbose = False\n",
    "df_count_wil = pd.DataFrame()\n",
    "df_count_wil = pd.concat([df_dm.mean(),df_dm.std(),df_gm.mean(),df_gm.std(),df_dq.mean(),df_dq.std()],axis=1)\n",
    "df_count_wil.columns = ['DTI_MSMT_mean','DTI_MSMT_std','GQI_MSMT_mean','GQI_MSMT_std','DTI_GQI_mean','DTI_GQI_std']\n",
    "df_count_wil.to_csv(main_path+'/stats/walk_4_count_wilcoxon_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_619693/248381940.py:16: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sh_dm.mean().to_csv(main_path+'/walk_4_DTI_msmt_volume_weighted_shapiro_wilk_results_mean.csv')\n",
      "/tmp/ipykernel_619693/248381940.py:17: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sh_dm.std().to_csv(main_path+'/walk_4_DTI_msmt_volume_weighted_shapiro_wilk_results_std.csv')\n",
      "/tmp/ipykernel_619693/248381940.py:24: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sh_gm.mean().to_csv(main_path+'/walk_4_GQI_msmt_volume_weighted_shapiro_wilk_results_mean.csv')\n",
      "/tmp/ipykernel_619693/248381940.py:25: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sh_gm.std().to_csv(main_path+'/walk_4_GQI_msmt_volume_weighted_shapiro_wilk_results_std.csv')\n",
      "/tmp/ipykernel_619693/248381940.py:32: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sh_dq.mean().to_csv(main_path+'/walk_4_DTI_GQI_volume_weighted_shapiro_wilk_results_mean.csv')\n",
      "/tmp/ipykernel_619693/248381940.py:33: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sh_dq.std().to_csv(main_path+'/walk_4_DTI_GQI_volume_weighted_shapiro_wilk_results_std.csv')\n",
      "/tmp/ipykernel_619693/248381940.py:65: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sh_dm.mean().to_csv(main_path+'/walk_4_DTI_msmt_count_shapiro_wilk_results_mean.csv')\n",
      "/tmp/ipykernel_619693/248381940.py:66: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sh_dm.std().to_csv(main_path+'/walk_4_DTI_msmt_count_shapiro_wilk_results_std.csv')\n",
      "/tmp/ipykernel_619693/248381940.py:73: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sh_gm.mean().to_csv(main_path+'/walk_4_GQI_msmt_count_shapiro_wilk_results_mean.csv')\n",
      "/tmp/ipykernel_619693/248381940.py:74: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sh_gm.std().to_csv(main_path+'/walk_4_GQI_msmt_count_shapiro_wilk_results_std.csv')\n",
      "/tmp/ipykernel_619693/248381940.py:81: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sh_dq.mean().to_csv(main_path+'/walk_4_DTI_GQI_count_shapiro_wilk_results_mean.csv')\n",
      "/tmp/ipykernel_619693/248381940.py:82: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sh_dq.std().to_csv(main_path+'/walk_4_DTI_GQI_count_shapiro_wilk_results_std.csv')\n"
     ]
    }
   ],
   "source": [
    "# read in shapiro-wilk results from all batches in main_path/stats with walk length 4\n",
    "verbose = False\n",
    "main_path = '/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/stats/'\n",
    "\n",
    "shapiro_file_list = Path(main_path).glob('volume_*_walk_length_4_shapiro_wilk_results.csv')\n",
    "df_sh = pd.DataFrame()\n",
    "for sh_file in shapiro_file_list:\n",
    "    if verbose:\n",
    "        print(sh_file)\n",
    "    df_sh = pd.concat([df_sh,pd.read_csv(sh_file)],axis=0)\n",
    "df_sh_dm = get_df_int(df=df_sh, recon1='DTI Node Volume Weighted Streamline Count', recon2='MSMT CSD SIFT2 Node Volume Weighted Streamline Count', i=None)\n",
    "# get mean and standard deviation of W statistic and p-value\n",
    "if verbose:\n",
    "    print_stats(df=df_sh_dm)\n",
    "# save out mean, std to one csv\n",
    "df_sh_dm.mean().to_csv(main_path+'/walk_4_DTI_msmt_volume_weighted_shapiro_wilk_results_mean.csv')\n",
    "df_sh_dm.std().to_csv(main_path+'/walk_4_DTI_msmt_volume_weighted_shapiro_wilk_results_std.csv')\n",
    "\n",
    "df_sh_gm = get_df_int(df=df_sh, recon1='GQI Node Volume Weighted Streamline Count', recon2='MSMT CSD SIFT2 Node Volume Weighted Streamline Count', i=None)\n",
    "# get mean and standard deviation of W statistic and p-value\n",
    "if verbose:\n",
    "    print_stats(df=df_sh_gm)\n",
    "# save out mean, std to one csv\n",
    "df_sh_gm.mean().to_csv(main_path+'/walk_4_GQI_msmt_volume_weighted_shapiro_wilk_results_mean.csv')\n",
    "df_sh_gm.std().to_csv(main_path+'/walk_4_GQI_msmt_volume_weighted_shapiro_wilk_results_std.csv')\n",
    "\n",
    "df_sh_dq = get_df_int(df=df_sh, recon1='DTI Node Volume Weighted Streamline Count', recon2='GQI Node Volume Weighted Streamline Count', i=None)\n",
    "# get mean and standard deviation of W statistic and p-value\n",
    "if verbose:\n",
    "    print_stats(df=df_sh_dq)\n",
    "# save out mean, std to one csv\n",
    "df_sh_dq.mean().to_csv(main_path+'/walk_4_DTI_GQI_volume_weighted_shapiro_wilk_results_mean.csv')\n",
    "df_sh_dq.std().to_csv(main_path+'/walk_4_DTI_GQI_volume_weighted_shapiro_wilk_results_std.csv')\n",
    "\n",
    "# read in mean and std files for shapiro-wilk at walk 4, summarize results for different recon1 reecon2 combinations\n",
    "verbose = False\n",
    "shapiro_list = ['walk_4_DTI_msmt_volume_weighted_shapiro_wilk_results_mean.csv',\n",
    "              'walk_4_DTI_msmt_volume_weighted_shapiro_wilk_results_std.csv',\n",
    "              'walk_4_DTI_GQI_volume_weighted_shapiro_wilk_results_mean.csv',\n",
    "              'walk_4_DTI_GQI_volume_weighted_shapiro_wilk_results_std.csv',\n",
    "              'walk_4_GQI_msmt_volume_weighted_shapiro_wilk_results_mean.csv',\n",
    "              'walk_4_GQI_msmt_volume_weighted_shapiro_wilk_results_std.csv']\n",
    "df_summary = pd.DataFrame()\n",
    "for s_file in shapiro_list:\n",
    "    if verbose:\n",
    "        print(s_file)\n",
    "    df = pd.read_csv(main_path+'/'+s_file, index_col=0)\n",
    "    df_summary = pd.concat([df_summary,df],axis=1)\n",
    "\n",
    "df_summary.columns = ['DTI MSMT mean', 'DTI MSMT std', 'DTI GQI mean', 'DTI GQI std', 'GQI MSMT mean', 'GQI MSMT std']\n",
    "df_summary.to_csv(main_path+'/walk_4_volume_weighted_shapiro_wilk_summary.csv')\n",
    "\n",
    "\n",
    "shapiro_file_list = Path(main_path).glob('count_*_walk_length_4_shapiro_wilk_results.csv')\n",
    "df_sh = pd.DataFrame()\n",
    "for sh_file in shapiro_file_list:\n",
    "    if verbose:\n",
    "        print(sh_file)\n",
    "    df_sh = pd.concat([df_sh,pd.read_csv(sh_file)],axis=0)\n",
    "df_sh_dm = get_df_int(df=df_sh, recon1='DTI Streamline Count', recon2='MSMT CSD SIFT2 Streamline Count', i=None)\n",
    "# get mean and standard deviation of W statistic and p-value\n",
    "if verbose:\n",
    "    print_stats(df=df_sh_dm)\n",
    "# save out mean, std to one csv\n",
    "df_sh_dm.mean().to_csv(main_path+'/walk_4_DTI_msmt_count_shapiro_wilk_results_mean.csv')\n",
    "df_sh_dm.std().to_csv(main_path+'/walk_4_DTI_msmt_count_shapiro_wilk_results_std.csv')\n",
    "\n",
    "df_sh_gm = get_df_int(df=df_sh, recon1='GQI Streamline Count', recon2='MSMT CSD SIFT2 Streamline Count', i=None)\n",
    "# get mean and standard deviation of W statistic and p-value\n",
    "if verbose:\n",
    "    print_stats(df=df_sh_gm)\n",
    "# save out mean, std to one csv\n",
    "df_sh_gm.mean().to_csv(main_path+'/walk_4_GQI_msmt_count_shapiro_wilk_results_mean.csv')\n",
    "df_sh_gm.std().to_csv(main_path+'/walk_4_GQI_msmt_count_shapiro_wilk_results_std.csv')\n",
    "\n",
    "df_sh_dq = get_df_int(df=df_sh, recon1='DTI Streamline Count', recon2='GQI Streamline Count', i=None)\n",
    "# get mean and standard deviation of W statistic and p-value\n",
    "if verbose:\n",
    "    print_stats(df=df_sh_dq)\n",
    "# save out mean, std to one csv\n",
    "df_sh_dq.mean().to_csv(main_path+'/walk_4_DTI_GQI_count_shapiro_wilk_results_mean.csv')\n",
    "df_sh_dq.std().to_csv(main_path+'/walk_4_DTI_GQI_count_shapiro_wilk_results_std.csv')\n",
    "\n",
    "# read in mean and std files for shapiro-wilk at walk 4, summarize results for different recon1 reecon2 combinations\n",
    "verbose = False\n",
    "shapiro_list = ['walk_4_DTI_msmt_count_shapiro_wilk_results_mean.csv',\n",
    "              'walk_4_DTI_msmt_count_shapiro_wilk_results_std.csv',\n",
    "              'walk_4_DTI_GQI_count_shapiro_wilk_results_mean.csv',\n",
    "              'walk_4_DTI_GQI_count_shapiro_wilk_results_std.csv',\n",
    "              'walk_4_GQI_msmt_count_shapiro_wilk_results_mean.csv',\n",
    "              'walk_4_GQI_msmt_count_shapiro_wilk_results_std.csv']\n",
    "df_summary = pd.DataFrame()\n",
    "for s_file in shapiro_list:\n",
    "    if verbose:\n",
    "        print(s_file)\n",
    "    df = pd.read_csv(main_path+'/'+s_file, index_col=0)\n",
    "    df_summary = pd.concat([df_summary,df],axis=1)\n",
    "\n",
    "df_summary.columns = ['DTI MSMT mean', 'DTI MSMT std', 'DTI GQI mean', 'DTI GQI std', 'GQI MSMT mean', 'GQI MSMT std']\n",
    "df_summary.to_csv(main_path+'/walk_4_count_shapiro_wilk_summary.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in paired t-test results from all batches in main_path/stats with walk length 4\n",
    "main_path = '/home/paul/thesis/dev/SAY_sf_prediction_v4/dataset/'\n",
    "# main_path = '/home/paul/thesis/dev/SAY_sf_prediction_v3/scrambled_dataset/'\n",
    "file_list = Path(main_path+'/stats').glob('mean_length_*_walk_length_4_ttest_rel_results.csv')\n",
    "df_ii = pd.DataFrame()\n",
    "for file in file_list:\n",
    "    if verbose:\n",
    "        print(file)\n",
    "    df_ii = pd.concat([df,pd.read_csv(file)],axis=0)\n",
    "df_dm = get_df_int(df=df_ii, recon1='DTI Mean Length', recon2='MSMT CSD Mean Length', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_dm)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_dm.mean().to_csv(main_path+'/stats/walk_4_DTI_msmt_mean_length_wilcoxon_results_mean.csv')\n",
    "df_dm.std().to_csv(main_path+'/stats/walk_4_DTI_msmt_mean_length_wilcoxon_results_std.csv')\n",
    "df_dm.max().to_csv(main_path+'/stats/walk_4_DTI_msmt_mean_length_wilcoxon_results_max.csv')\n",
    "df_dm.min().to_csv(main_path+'/stats/walk_4_DTI_msmt_mean_length_wilcoxon_results_min.csv')\n",
    "\n",
    "df_gm = get_df_int(df=df_ii, recon1='GQI Mean Length', recon2='MSMT CSD Mean Length', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_gm)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_gm.mean().to_csv(main_path+'/stats/walk_4_GQI_msmt_mean_length_wilcoxon_results_mean.csv')\n",
    "df_gm.std().to_csv(main_path+'/stats/walk_4_GQI_msmt_mean_length_wilcoxon_results_std.csv')\n",
    "df_gm.max().to_csv(main_path+'/stats/walk_4_GQI_msmt_mean_length_wilcoxon_results_max.csv')\n",
    "df_gm.min().to_csv(main_path+'/stats/walk_4_GQI_msmt_mean_length_wilcoxon_results_min.csv')\n",
    "\n",
    "df_dq = get_df_int(df=df_ii, recon1='DTI Mean Length', recon2='GQI Mean Length', i=None)\n",
    "# get mean and standard deviation, max, min of t-statistic and p-value for the row where Recon 1 is DTI Node Volume Weighted Streamline Count and Recon 2 is MSMT CSD SIFT2 Node Volume Weighted Streamline Count\n",
    "if verbose:\n",
    "    print_stats(df=df_dq)\n",
    "# save out mean, std, max, min to one csv\n",
    "df_dq.mean().to_csv(main_path+'/stats/walk_4_DTI_GQI_mean_length_wilcoxon_results_mean.csv')\n",
    "df_dq.std().to_csv(main_path+'/stats/walk_4_DTI_GQI_mean_length_wilcoxon_results_std.csv')\n",
    "df_dq.max().to_csv(main_path+'/stats/walk_4_DTI_GQI_mean_length_wilcoxon_results_max.csv')\n",
    "df_dq.min().to_csv(main_path+'/stats/walk_4_DTI_GQI_mean_length_wilcoxon_results_min.csv')\n",
    "\n",
    "# combine all volume weighted wilcoxon signed rank test results at walk length 4\n",
    "verbose = False\n",
    "df_ml_wil = pd.DataFrame()\n",
    "df_ml_wil = pd.concat([df_dm.mean(),df_dm.std(),df_gm.mean(),df_gm.std(),df_dq.mean(),df_dq.std()],axis=1)\n",
    "df_ml_wil.columns = ['DTI_MSMT_mean','DTI_MSMT_std','GQI_MSMT_mean','GQI_MSMT_std','DTI_GQI_mean','DTI_GQI_std']\n",
    "df_ml_wil.to_csv(main_path+'/stats/walk_4_mean_length_wilcoxon_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro_file_list = Path(main_path).glob('mean_path_length_*_walk_length_4_shapiro_wilk_results.csv')\n",
    "df_sh = pd.DataFrame()\n",
    "for sh_file in shapiro_file_list:\n",
    "    if verbose:\n",
    "        print(sh_file)\n",
    "    df_sh = pd.concat([df_sh,pd.read_csv(sh_file)],axis=0)\n",
    "df_sh_dm = get_df_int(df=df_sh, recon1='DTI Mean Length', recon2='MSMT CSD Mean Length', i=None)\n",
    "# get mean and standard deviation of W statistic and p-value\n",
    "if verbose:\n",
    "    print_stats(df=df_sh_dm)\n",
    "# save out mean, std to one csv\n",
    "df_sh_dm.mean().to_csv(main_path+'/walk_4_DTI_msmt_mean_length_shapiro_wilk_results_mean.csv')\n",
    "df_sh_dm.std().to_csv(main_path+'/walk_4_DTI_msmt_mean_length_shapiro_wilk_results_std.csv')\n",
    "\n",
    "df_sh_gm = get_df_int(df=df_sh, recon1='GQI Mean Length', recon2='MSMT CSD Mean Length', i=None)\n",
    "# get mean and standard deviation of W statistic and p-value\n",
    "if verbose:\n",
    "    print_stats(df=df_sh_gm)\n",
    "# save out mean, std to one csv\n",
    "df_sh_gm.mean().to_csv(main_path+'/walk_4_GQI_msmt_mean_length_shapiro_wilk_results_mean.csv')\n",
    "df_sh_gm.std().to_csv(main_path+'/walk_4_GQI_msmt_mean_length_shapiro_wilk_results_std.csv')\n",
    "\n",
    "df_sh_dq = get_df_int(df=df_sh, recon1='DTI Mean Length', recon2='GQI Mean Length', i=None)\n",
    "# get mean and standard deviation of W statistic and p-value\n",
    "if verbose:\n",
    "    print_stats(df=df_sh_dq)\n",
    "# save out mean, std to one csv\n",
    "df_sh_dq.mean().to_csv(main_path+'/walk_4_DTI_GQI_mean_length_shapiro_wilk_results_mean.csv')\n",
    "df_sh_dq.std().to_csv(main_path+'/walk_4_DTI_GQI_mean_length_shapiro_wilk_results_std.csv')\n",
    "\n",
    "# read in mean and std files for shapiro-wilk at walk 4, summarize results for different recon1 reecon2 combinations\n",
    "verbose = False\n",
    "shapiro_list = ['walk_4_DTI_msmt_mean_length_shapiro_wilk_results_mean.csv',\n",
    "              'walk_4_DTI_msmt_mean_length_shapiro_wilk_results_std.csv',\n",
    "              'walk_4_DTI_GQI_mean_length_shapiro_wilk_results_mean.csv',\n",
    "              'walk_4_DTI_GQI_mean_length_shapiro_wilk_results_std.csv',\n",
    "              'walk_4_GQI_msmt_mean_length_shapiro_wilk_results_mean.csv',\n",
    "              'walk_4_GQI_msmt_mean_length_shapiro_wilk_results_std.csv']\n",
    "df_summary = pd.DataFrame()\n",
    "for s_file in shapiro_list:\n",
    "    if verbose:\n",
    "        print(s_file)\n",
    "    df = pd.read_csv(main_path+'/'+s_file, index_col=0)\n",
    "    df_summary = pd.concat([df_summary,df],axis=1)\n",
    "\n",
    "df_summary.columns = ['DTI MSMT mean', 'DTI MSMT std', 'DTI GQI mean', 'DTI GQI std', 'GQI MSMT mean', 'GQI MSMT std']\n",
    "df_summary.to_csv(main_path+'/walk_4_mean_length_shapiro_wilk_summary.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
